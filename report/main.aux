\relax 
\bibstyle{plainnat}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Maximum Location Discovery: A Greedy Approach}{2}{}\protected@file@percent }
\newlabel{sec:greedy}{{2}{2}{}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Real-World Problem: Location Discovery Through Social Connections}{2}{}\protected@file@percent }
\newlabel{sec:greedy-real-problem}{{2.1}{2}{}{subsection.2.1}{}}
\citation{Karp1972}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Problem Abstraction: Maximum Coverage}{3}{}\protected@file@percent }
\newlabel{sec:greedy-abstraction}{{2.2}{3}{}{subsection.2.2}{}}
\newlabel{def:max-coverage}{{1}{3}{}{theorem.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Greedy Algorithm Solution}{3}{}\protected@file@percent }
\newlabel{sec:greedy-algorithm}{{2.3}{3}{}{subsection.2.3}{}}
\@writefile{lop}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Greedy Maximum Coverage}}{4}{}\protected@file@percent }
\newlabel{alg:greedy-coverage}{{1}{4}{}{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Time Complexity Analysis}{4}{}\protected@file@percent }
\newlabel{sec:greedy-complexity}{{2.4}{4}{}{subsection.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Proof of Correctness}{5}{}\protected@file@percent }
\newlabel{sec:greedy-correctness}{{2.5}{5}{}{subsection.2.5}{}}
\newlabel{lem:coverage-submodular}{{4}{5}{}{theorem.4}{}}
\citation{Nemhauser1978}
\newlabel{thm:greedy-approximation}{{5}{6}{}{theorem.5}{}}
\citation{Feige1998}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Domain-Specific Explanation}{7}{}\protected@file@percent }
\newlabel{sec:greedy-domain}{{2.6}{7}{}{subsection.2.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Greedy algorithm execution for Alice's location discovery}}{8}{}\protected@file@percent }
\newlabel{tab:greedy-example}{{1}{8}{}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Experimental Validation}{8}{}\protected@file@percent }
\newlabel{sec:greedy-experiments}{{2.7}{8}{}{subsection.2.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Discovering Near-Miss Connections: A Divide \& Conquer Approach}{8}{}\protected@file@percent }
\newlabel{sec:divide-conquer}{{3}{8}{}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Real-World Problem: Finding Near-Miss Encounters}{8}{}\protected@file@percent }
\newlabel{sec:dc-real-problem}{{3.1}{8}{}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Problem Abstraction: Closest Pair of Points}{9}{}\protected@file@percent }
\newlabel{sec:dc-abstraction}{{3.2}{9}{}{subsection.3.2}{}}
\newlabel{def:closest-pair}{{6}{9}{}{theorem.6}{}}
\citation{Shamos1975}
\@writefile{lop}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Divide and Conquer Closest Pair}}{10}{}\protected@file@percent }
\newlabel{alg:closest-pair}{{2}{10}{}{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Divide and Conquer Algorithm Solution}{10}{}\protected@file@percent }
\newlabel{sec:dc-algorithm}{{3.3}{10}{}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Time Complexity Analysis}{11}{}\protected@file@percent }
\newlabel{sec:dc-complexity}{{3.4}{11}{}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Proof of Correctness}{12}{}\protected@file@percent }
\newlabel{sec:dc-correctness}{{3.5}{12}{}{subsection.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Domain-Specific Explanation}{13}{}\protected@file@percent }
\newlabel{sec:dc-domain}{{3.6}{13}{}{subsection.3.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces User locations for closest pair example}}{13}{}\protected@file@percent }
\newlabel{tab:dc-example}{{2}{13}{}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Experimental Validation}{14}{}\protected@file@percent }
\newlabel{sec:dc-experiments}{{3.7}{14}{}{subsection.3.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Validation}{15}{}\protected@file@percent }
\newlabel{sec:experiments}{{4}{15}{}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Experimental Setup}{15}{}\protected@file@percent }
\newlabel{sec:exp-setup}{{4.1}{15}{}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Experiment 1: Runtime Scalability}{15}{}\protected@file@percent }
\newlabel{sec:exp-runtime}{{4.2}{15}{}{subsection.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Runtime vs number of users (n). The algorithm exhibits linear scaling with n, confirming O(k·n·m) complexity. Error bars show standard deviation across 10 trials. The dashed line is a least-squares linear fit.}}{15}{}\protected@file@percent }
\newlabel{fig:runtime-vs-n}{{4.2}{15}{}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Experiment 2: Coverage Quality (Greedy vs Random)}{16}{}\protected@file@percent }
\newlabel{sec:exp-coverage}{{4.3}{16}{}{subsection.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Coverage (unique locations discovered) vs number of friends selected (k). Greedy selection consistently outperforms random selection by 25-60\%, with an average improvement of 41\%. The plot demonstrates diminishing returns: marginal gain decreases as k increases.}}{16}{}\protected@file@percent }
\newlabel{fig:coverage-vs-k}{{4.3}{16}{}{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Coverage comparison: Greedy vs Random selection}}{16}{}\protected@file@percent }
\newlabel{tab:coverage-comparison}{{3}{16}{}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Experiment 3: Approximation Ratio (Greedy vs Optimal)}{16}{}\protected@file@percent }
\newlabel{sec:exp-approximation}{{4.4}{16}{}{subsection.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Left: Approximation ratio (greedy coverage / optimal coverage) across different problem sizes. All instances achieve ratio $\geq 0.98$, far exceeding the theoretical guarantee of 0.632 (dashed red line). Bars are green when above guarantee. Right: Runtime comparison showing exponential growth of brute force (log scale) vs linear growth of greedy.}}{17}{}\protected@file@percent }
\newlabel{fig:approximation-ratio}{{4.4}{17}{}{figure.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Approximation ratio and runtime comparison}}{17}{}\protected@file@percent }
\newlabel{tab:approximation-ratio}{{4}{17}{}{table.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Experiment 4: Performance on Realistic Data}{17}{}\protected@file@percent }
\newlabel{sec:exp-zipf}{{4.5}{17}{}{subsection.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Performance on Zipf-distributed data (realistic popularity). Greedy maintains 30-50\% improvement over random even when location popularity is skewed, demonstrating robustness to real-world data characteristics.}}{17}{}\protected@file@percent }
\newlabel{fig:zipf}{{4.5}{17}{}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Experiment 5: Closest Pair Runtime Comparison}{18}{}\protected@file@percent }
\newlabel{sec:exp-closest-runtime}{{4.6}{18}{}{subsection.4.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Runtime comparison: Divide \& Conquer vs Brute Force. Left: Absolute runtime showing DC remains efficient while BF becomes impractical. Right: Log-scale plot showing exponential growth of brute force vs linear growth (on log scale) of DC. At n=5000, DC achieves 2.9$\times $ speedup.}}{18}{}\protected@file@percent }
\newlabel{fig:closest-runtime}{{4.6}{18}{}{figure.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Runtime comparison: DC vs Brute Force}}{18}{}\protected@file@percent }
\newlabel{tab:closest-runtime}{{5}{18}{}{table.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Experiment 6: Complexity Verification}{18}{}\protected@file@percent }
\newlabel{sec:exp-closest-complexity}{{4.7}{18}{}{subsection.4.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Complexity verification for O(n log n). Left: Actual runtime (dots) vs fitted O(n log n) curve (dashed), showing excellent agreement. Right: Normalized runtime (runtime/n log n) remains approximately constant across all n, confirming O(n log n) complexity. Mean = 0.000039, coefficient of variation = 16\%.}}{19}{}\protected@file@percent }
\newlabel{fig:closest-complexity}{{4.7}{19}{}{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Experiment 7: Performance on Different Distributions}{19}{}\protected@file@percent }
\newlabel{sec:exp-closest-distributions}{{4.8}{19}{}{subsection.4.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Performance on different data distributions. Left: Runtime remains consistent across uniform and clustered data. Right: Number of distance comparisons is slightly higher for clustered data but still O(n log n). Algorithm is robust to spatial distribution.}}{19}{}\protected@file@percent }
\newlabel{fig:closest-distributions}{{4.8}{19}{}{figure.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Performance across distributions}}{19}{}\protected@file@percent }
\newlabel{tab:closest-distributions}{{6}{19}{}{table.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9}Discussion}{20}{}\protected@file@percent }
\newlabel{sec:exp-discussion}{{4.9}{20}{}{subsection.4.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.10}Summary}{20}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Summary: Greedy Maximum Coverage}}{20}{}\protected@file@percent }
\newlabel{tab:experiment-summary-greedy}{{7}{20}{}{table.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Summary: Divide \& Conquer Closest Pair}}{21}{}\protected@file@percent }
\newlabel{tab:experiment-summary-dc}{{8}{21}{}{table.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{21}{}\protected@file@percent }
\newlabel{sec:conclusion}{{5}{21}{}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Problem 1: Maximum Location Discovery (Greedy)}{21}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Problem 2: Closest Pair (Divide \& Conquer)}{21}{}\protected@file@percent }
\bibdata{references}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Comparative Analysis}{22}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Summary of algorithmic approaches}}{22}{}\protected@file@percent }
\newlabel{tab:comparison}{{9}{22}{}{table.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Practical Impact}{22}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Future Directions}{22}{}\protected@file@percent }
\@writefile{lop}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Recursive Closest Pair Helper}}{23}{}\protected@file@percent }
\newlabel{alg:closest-pair-recursive}{{3}{23}{}{algorithm.3}{}}
\@writefile{lop}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Find Closest Pair in Strip}}{24}{}\protected@file@percent }
\newlabel{alg:strip-closest}{{4}{24}{}{algorithm.4}{}}
\gdef \@abspage@last{24}
